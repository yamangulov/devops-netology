
# Домашнее задание к занятию "5.1. Введение в виртуализацию. Типы и функции гипервизоров. Обзор рынка вендоров и областей применения."

## Задача 1

Опишите кратко, как вы поняли: в чем основное отличие полной (аппаратной) виртуализации, паравиртуализации и виртуализации на основе ОС.

- полная (аппаратная виртуализация) - гипервизор является первым слоем поверх железа и именно он имеет прямой доступ к аппаратным ресурсам, он же модифицирует настройки доступа к этим ресурсам, ограничивает и разделяет их, а уже затем предоставляет гостевым ОС. В результате управление ресурсами происходит на очень низком уровне и требует меньше затрат, гипервизор самый "легкий" и быстродействующий в сравнении с другими типами виртуализации, как я понимаю. Переключение виртуальных машин идет на аппаратном уровне, разделение ресурсов тоже на аппаратном уровне, и поэтому изолированность и защищенность гостевых ОС максимальная. Гостевая ОС не привязана к архитектуре гипервизора и поэтому можно запускать ОС с другой архитектурой, например, 64 битные гостевые машины на 32 битном хосте.
- паравиртуализация - гипервизор является вторым слоем поверх железа + некоторой базовой ОС, то есть фактически гипервизор является программой, запускаемой в этой ОС. Гипервизор реализует некий API для подключения к нему и получения доступа к аппаратным ресурсам, прямого доступа к ресурсам гостевые ОС не имеют, а обязаны работать, используя этот API. Поэтому возникает необходимость немного модифицировать ядра гостевых ОС, чтобы они могли так делать. Поэтому нужно, чтобы гостевые ОС имели открытый код либо вендор закрытой ОС предоставлял поддержку для своих ОС, чтобы их можно было использовать в паравиртуализации. Трудно сказать, но я предполагаю, что паравиртуализация возникла прежде всего, чтобы позволить сэкономить в ряде случаев - использовать для виртуализации уже ранее запущенные серверы с хозяйской ОС, когда они исторически выполняют еще какие-то нужные функции, и необходимо сохранить эти функции, не переустанавливая начисто хозяйскую ОС, а просто свободные остальные ресурсы использовать для гостевых ОС.
- виртуализация на основе ОС - это фактически контейнеризация, то есть нет какого-то отдельного гипервизора, распределяющего ресурсы, а используются собственные встроенные средства хозяйской ОС для разделения ресурсов и процессов. То есть создается "песочница" - изолированное пространство пользователя, "контейнер", "зона". Поскольку используются те же процессы, что и в хозяйской ОС, то гостевая ОС фактически использует то же самое ядро и аппартаные ресурсы. Это - ограничение на запуск типов ОС, они должны быть совместимы с ядром хозяйской ОС. Но при этом не нужно эмулировать отдельную ОС для запуска, и это очень сильно экономит ресурсы. В настоящее время широко используется как разработчиками ПО в повседневной работе, так и для запуска в production среде, и даже многие считают, что контейнеризация вытесняет остальные виды виртуализации. Вероятно, есть кейсы, где это не так, и тому есть причины, но мне за последние два года ни разу не попадался кейс, отличный от контейнеризации.

## Задача 2

Выберите один из вариантов использования организации физических серверов, в зависимости от условий использования.

Организация серверов:
- физические сервера,
- паравиртуализация,
- виртуализация уровня ОС.

Условия использования:
- Высоконагруженная база данных, чувствительная к отказу.
- Различные web-приложения.
- Windows системы для использования бухгалтерским отделом.
- Системы, выполняющие высокопроизводительные расчеты на GPU.

Опишите, почему вы выбрали к каждому целевому использованию такую организацию.

- Высоконагруженная база данных, чувствительная к отказу.

Я бы выбрал паравиртуализацию с регулярными автоматическими снапшотами, с тем, чтобы можно было очень быстро запустить последний валидный снапшот, причем должно быть настроено постоянное автоматическое бэкапирование снапшотов на альтернативные резервные аппаратные серверы. При падении БД быстро запускаем последний валидный снапшот именно на резервном аппаратном сервере, а потом спокойно разбираемся с основным. Потому что падение БД могло быть вызвано как проблемой при некорректной работе с БД (тяжелые или вредоносные запросы, пропущенные системой безопасности БД, например), так и аппаратной проблемой - и тогда мы потеряем время на повторые попытки поднять аппаратно поврежденный сервер.

Однако, можно сделать аналогичную по качеству среду и на основе контейнеризации, только это потребует больше усилий и дополнительное использование оркестраторов (например, kubernetes), а мы до них пока еще не дошли в нашем курсе

- Различные web-приложения.

Здесь обычно вполне достаточно виртуализации уровня ОС, я предполагаю, что само web-приложение грамотно разделено уровнем хранения данных. Легко и быстро можно заменять поврежденные контейнеры, давать им больше или меньше ресурсов, например, используя docker-compose (вручную) или kubernetes (автоматическое масшатабирование и восстановление после сбоев). Случаи тяжелого web-приложения с неграмотно разделенными уровнями я не рассматриваю - их нужно рефакторить, для того чтобы подготовить к виртализации, они будут одинаково плохо работать везде, если уровни приложения не разделены.


- Windows системы для использования бухгалтерским отделом.

Я бы использовал решение на основе Hyper-V для максимальной совместимости со средой предприятия на основе Active Directory

- Системы, выполняющие высокопроизводительные расчеты на GPU.

Это наиболее трудный вопрос для меня, так как я еще никогда не занимался такими кейсами, но могу предположить, что качественное взаимодействие с GPU пока что осуществляется только на полноценном наборе вызовов ядра, и скорее всего, оптимально использовать аппаратную виртуализацию, потому что она не будет искажать аппаратные вызовы и имеет полный доступ к ним всем, что важно для работы с GPU хозяйской ОС. Поэтому я бы выбрал именно аппаратную виртуализацию.

## Задача 3

Выберите подходящую систему управления виртуализацией для предложенного сценария. Детально опишите ваш выбор.

Сценарии:

1. 100 виртуальных машин на базе Linux и Windows, общие задачи, нет особых требований. Преимущественно Windows based инфраструктура, требуется реализация программных балансировщиков нагрузки, репликации данных и автоматизированного механизма создания резервных копий.

В принципе, наиболее подходит Hyper-V - хорошо совместима со средой Windows, но позволяет запускать и linux, балансировщик нагрузки есть, репликация и автоматическое резервное копирование по расписанию тоже есть, например, Windows Server Backup с встроенной графической админкой wbadmin.msc (также есть и сторонние средства, если этого недостаточно - Veritas Backup Exec, Commvault Backup, Veeam Backup,  Acronis Backup)

2. Требуется наиболее производительное бесплатное open source решение для виртуализации небольшой (20-30 серверов) инфраструктуры на базе Linux и Windows виртуальных машин.

Я бы выбрал Xen PV, так как он более стабилен, чем KVM, и более совместим с Windows, чем Xen HVM. А производительность у Xen и KVM, мне показалось, мало отличается, тут главное - проверенное стабильное решение для продуктивной среды

3. Необходимо бесплатное, максимально совместимое и производительное решение для виртуализации Windows инфраструктуры.

Также выбрал бы Xen PV, по тем же причинам, кейс мало отличается от предыдущего, разве что отсутствием linux

4. Необходимо рабочее окружение для тестирования программного продукта на нескольких дистрибутивах Linux.

Здесь подходит виртуализация на основе ОС, можно воспользоваться docker контейнерами, что обычно и делают

## Задача 4

Опишите возможные проблемы и недостатки гетерогенной среды виртуализации (использования нескольких систем управления виртуализацией одновременно) и что необходимо сделать для минимизации этих рисков и проблем. Если бы у вас был выбор, то создавали бы вы гетерогенную среду или нет? Мотивируйте ваш ответ примерами.

Многие форматы хранения виртуальных машин из разных сред виртуализации несовместимы между собой, а если совместимы, то требуется значительное время на перенос из одной среды в другую (а иногда это вообще невозможно), для автоматического бэкапирования нужно писать какие-то свои кастомные решения (да и то, если перенос возможен), больше усилий на поддержку, необходимы квалифицированные специалисты, которые разбираются во всех средах виртуализации. Я бы вообще не использовал такую среду. Но полагаю, что она была бы необходима, если у нас в принципе гетерогенный набор ОС с очень разными требованиям, например, есть пул Windows и linux серверов и рабочих станций с существенно разными требованиями к производительности и к поддержке пользовательского ПО, и при этом недостаточно средств для дорогостоящей универсальной среды виртуализации, подобной VSphere или Citrix Xen. Тогда я выделил бы несколько групп сред виртуализации, по одной для каждого типа серверов с условием, что виртуальные машины перемещаются и бекапируются только внутри каждой отдельной группы, а взаимодействие между машинами разных групп осуществляются только на уровне приложений или по сетевым протоколам. Например, делаем группу Hyper-V для среды Windows машин отдельную и группу Xen HVM для linux серверов отдельную, резервные серверы организуем только внутри каждой группы. Это снизит проблемы, но на самом деле создает не одну гетерогенную среду виртуализации, а две отдельные, параллельно работающие.